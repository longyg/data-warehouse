<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <!-- 开启集群高可用(HA)-->
    <property>
        <name>yarn.resourcemanager.ha.enabled</name>
        <value>true</value>
    </property>
    <!-- 指定RM的cluster id -->
    <property>
        <name>yarn.resourcemanager.cluster-id</name>
        <value>rmcluster</value>
    </property>
    <!-- 指定两个RM的节点id-->
    <property>
        <name>yarn.resourcemanager.ha.rm-ids</name>
        <value>rm1,rm2</value>
    </property>
    <!-- 指定两个RM节点的host-->
    <property>
        <name>yarn.resourcemanager.hostname.rm1</name>
        <value>bigdata01</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname.rm2</name>
        <value>bigdata02</value>
    </property>
    <!-- RM的http服务端口-->
    <property>
        <name>yarn.resourcemanager.webapp.address.rm1</name>
        <value>bigdata01:8088</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address.rm2</name>
        <value>bigdata02:8088</value>
    </property>
    <!-- RM的applications manager(ASM)端口-->
    <property>
        <name>yarn.resourcemanager.address.rm1</name>
        <value>bigdata01:8032</value>
    </property>
    <property>
        <name>yarn.resourcemanager.address.rm2</name>
        <value>bigdata02:8032</value>
    </property>
    <!-- 指定两个RM节点调度程序接口的地址，scheduler组件的IPC端口-->
    <property>
        <name>yarn.resourcemanager.scheduler.address.rm1</name>
        <value>bigdata01:8030</value>
    </property>
    <property>
        <name>yarn.resourcemanager.scheduler.address.rm2</name>
        <value>bigdata02:8030</value>
    </property>
    <!--指定两个RM节点的管理界面的地址 -->
    <property>
        <name>yarn.resourcemanager.admin.address.rm1</name>
        <value>bigdata01:8033</value>
    </property>
    <property>
        <name>yarn.resourcemanager.admin.address.rm2</name>
        <value>bigdata02:8033</value>
    </property>
    <!--NM通过该地址交换信息-->
    <property>
        <name>yarn.resourcemanager.resource-tracker.address.rm1</name>
        <value>bigdata01:8031</value>
    </property>
    <property>
        <name>yarn.resourcemanager.resource-tracker.address.rm2</name>
        <value>bigdata02:8031</value>
    </property>
    <!-- 指定zk地址-->
    <property>
        <name>yarn.resourcemanager.zk-address</name>
        <value>bigdata01:2181,bigdata02:2181,bigdata03:2181</value>
    </property>
    <!--等待节点管理器被认为已经死亡的时间，默认10分钟-->
    <property>
        <name>yarn.nm.liveness-monitor.expiry-interval-ms</name>
        <value>100000</value>
    </property>
    <!--是否使用用户名关联分配的默认队列名称，如果是false或者未设置，所有的作业都有一个共享的默认队列，叫做default。默认是true, 如果是true，当任务中未指定资源池的时候，将以用户名作为资源池名。这个配置就实现了根据用户名自动分配资源池。-->
    <property>
        <name>yarn.scheduler.fair.user-as-default-queue</name>
        <value>false</value>
    </property>
    <!--容器执行类-->
    <property>
        <name>yarn.nodemanager.container-executor.class</name>
        <value>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor</value>
    </property>
    <!--是否将对容器强制实施物理内存限制。-->
    <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>true</value>
    </property>
    <!--是否启用自动故障转移-->
    <property>
        <name>yarn.resourcemanager.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>
    <!--yarn.nodemanager.resource.memory-mb   可以为容器分配的物理内存量（MB）。如果设置为-1且yarn.nodemanager.resource.detect-hardware-capabilities为true，则会自动计算（如果是Windows和Linux）。在其他情况下，默认值为8192MB-->。
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>2048</value>
    </property>
    <!--RM中每个容器请求的最大分配内存，以MB为单位。高于此的内存请求将抛出InvalidResourceRequestException-->。
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>12288</value>
    </property>
    <!--就虚拟CPU核心而言，RM上每个容器请求的最大分配。高于此的请求将抛出InvalidResourceRequestException-->
    <property>
        <name>yarn.scheduler.maximum-allocation-vcores</name>
        <value>32</value>
    </property>
    <!--schelduler失联等待连接时间-->
    <property>
        <name>yarn.app.mapreduce.am.scheduler.connection.wait.interval-ms</name>
        <value>5000</value>
    </property>
    <!--启动后启用RM以恢复状态。如果为true，则必须指定yarn.resourcemanager.store.class-->
    <property>
        <name>yarn.resourcemanager.recovery.enabled</name>
        <value>true</value>
    </property>
    <!--用作RM状态存储方式储的类-->
    <property>
        <name>yarn.resourcemanager.store.class</name>
        <value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>
    </property>
    <!--rm失联后重新链接的时间间隔-->
    <property>
        <name>yarn.resourcemanager.connect.retry-interval.ms</name>
        <value>2000</value>
    </property>
    <!--ZKRMStateStore连接的zk地址-->
    <property>
        <name>yarn.resourcemanager.zk.state-store.address</name>
        <value>bigdata01:2181,bigdata02:2181,bigdata03:2181</value>
    </property>
    <!--设置容器的内存限制时虚拟内存与物理内存之间的比率-->
    <property>
        <name>yarn.nodemanager.vmem-pmem-ratio</name>
        <value>8</value>
    </property>
    <!--是否启用日志聚合.日志聚合收集每个容器的日志，并在应用程序完成后将这些日志移动到文件系统，例如HDFS。用户可以配置“yarn.nodemanager.remote-app-log-dir”和“yarn.nodemanager.remote-app-log-dir-suffix”属性以确定这些日志的移动位置。用户可以通过应用程序时间线服务器访问日志。-->
    <property>
        <name>yarn.log-aggregation-enable</name>
        <value>true</value>
    </property>
    <!--日志聚合服务器的URL-->
    <property>
        <name>yarn.log.server.url</name>
        <value>http://bigdata01:19888/jobhistory/logs</value>
    </property>
    <!--聚合日志保留时间-->
    <property>
        <name>yarn.log-aggregation.retain-seconds</name>
        <value>604800</value>
    </property>
    <property>
        <name>yarn.nodemanager.log-dirs</name>
        <value>/opt/software/hadoop/yarn/logs</value>
    </property>
    <!--application执行结束后延迟该时间删除文件及日志，单位s-->
    <property>
        <name>yarn.nodemanager.delete.debug-delay-sec</name>
        <value>600</value>
    </property>
    <!--NN上日志聚集的位置（聚合日志后在hdfs的存放地址-->
    <property>
        <name>yarn.nodemanager.remote-app-log-dir</name>
        <value>/yarn-logs</value>
    </property>
    <!--hdfs上集合日志后的存放地址由 ${remote-app-log-dir}/${user}/{thisParam}构成-->
    <property>
        <name>yarn.nodemanager.remote-app-log-dir-suffix</name>
        <value>logs</value>
    </property>
    <!--存储本地化文件的目录列表。应用程序的本地化文件目录位于：$ {yarn.nodemanager.local-dirs} / usercache / $ {user} / appcache / application _ $ {appid}。单个容器的工作目录（称为container _ $ {contid}）将是其子目录-->
    <property>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/opt/software/hadoop/yarn/local</value>
    </property>
    <!--默认为/tmp/hadoop-yarn/staging。MR作业在提交时所使用的临时目录， 是一个本地路径-->
    <property>
        <name>yarn.app.mapreduce.am.staging-dir</name>
        <value>/opt/software/hadoop/yarn/staging</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
        <name>yarn.resourcemanager.scheduler.class</name>
        <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>
    </property>
    <!--可以为容器分配的vcores数。在为容器分配资源时，RM调度程序使用它。这不用于限制YARN容器使用的CPU数量。如果设置为-1且yarn.nodemanager.resource.detect-hardware-capabilities为true，则在Windows和Linux的情况下会自动从硬件确定。在其他情况下，默认情况下，vcores的数量为8。-->
<!--    <property>-->
<!--        <name>yarn.nodemanager.resource.cpu-vcores</name>-->
<!--        <value>8</value>-->
<!--    </property>-->
    <!--最大应用程序尝试次数。它是所有应用程序master的全局设置。每个应用程序主机都可以通过API指定其各自的最大应用程序尝试次数，但是单个数字不能超过全局上限。如果是，资源管理器将覆盖它。默认数量设置为2，以允许至少一次重试AM。-->
    <property>
        <name>yarn.resourcemanager.am.max-attempts</name>
        <value>5</value>
    </property>
    <!--RM中每个容器请求的最小分配（MB）内存-->
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>128</value>
    </property>
    <!--用于YarnAuthorizationProvider的类-->
    <!--<property>
      <name>yarn.authorization-provider</name>
      <value>org.apache.ranger.authorization.yarn.authorizer.RangerYarnAuthorizer</value>
    </property> -->
    <!--启用嵌入式自动故障转移。默认情况下，仅在启用HA时启用它。嵌入式选举器依赖RM状态存储来处理防护，主要用于与ZKRMStateStore结合使用。-->
    <property>
        <name>yarn.resourcemanager.ha.automatic-failover.embedded</name>
        <value>true</value>
    </property>
    <!--群集中每个NodeManager的心跳间隔（以毫秒为单位）-->
    <property>
        <name>yarn.resourcemanager.nodemanagers.heartbeat-interval-ms</name>
        <value>1000</value>
    </property>
    <!--linux-container-executor应该运行的UNIX组-->
    <property>
        <name>yarn.nodemanager.linux-container-executor.group</name>
        <value>bigdata</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.percentage-physical-cpu-limit</name>
        <value>100</value>
    </property>
    <property>
        <name>yarn.scheduler.minimum-allocation-vcores</name>
        <value>1</value>
    </property>
    <!--日志的保留时间,log aggregation没有enable时，有效-->
    <property>
        <name>yarn.nodemanager.log.retain-seconds</name>
        <value>604800</value>
    </property>
    <!--是否将对容器强制实施虚拟内存限制-->
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
    <!--RM保留的已完成应用程序的最大数量。-->
    <property>
        <name>yarn.resourcemanager.max-completed-applications</name>
        <value>150</value>
    </property>
    <!--<property>
      <name>yarn.scheduler.fair.allow-undeclared-pools</name>
      <value>false</value>
  </property>-->
    <!--在聚合日志保留检查之间等待多长时间。如果设置为0或负值，则该值将计算为聚合日志保留时间的十分之一。-->
    <property>
        <name>yarn.log-aggregation.retain-check-interval-seconds</name>
        <value>604800</value>
    </property>
    <!--<property>
      <name>yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user</name>
      <value>hadoop</value>
  </property>-->
    <!--帮助linux-container-executor处理资源的类-->
    <property>
        <name>yarn.nodemanager.linux-container-executor.resources-handler.class</name>
        <value>org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler</value>
    </property>
</configuration>